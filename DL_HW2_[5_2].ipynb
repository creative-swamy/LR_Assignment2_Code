{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DL-HW2-[5.2].ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "vXIAjCWTbn6n",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<center>\n",
        "##IFT 6135 : Representation Learning \n",
        "##Winter 2018\n",
        "  \n",
        "# ASSIGNMENT - 2 : PROGRAMMING PART\n",
        "# Problem (5.2) :  Detailed evaluation of trained models - Final-timestep Loss gradient norm\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Submitted by \n",
        "\n",
        "___________________________________________________\n",
        "\n",
        "\n",
        "\n",
        "## PRAVISH SAINATH\n",
        "####20125633\n",
        "####M.Sc. Informatique\n",
        "####Université de Montréal\n"
      ]
    },
    {
      "metadata": {
        "id": "RE1Ryepekhc2",
        "colab_type": "code",
        "outputId": "90b460e7-cfa9-4cfe-8425-9d5b723f1131",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "5zyMVJErkyCS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "DRIVE_PATH = 'drive/My Drive/DL/HW-2/experiments'\n",
        "%cd 'drive/My Drive/DL/HW-2/experiments'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VfoGHvM3k-uT",
        "colab_type": "code",
        "outputId": "41fe6fe9-bc70-4ff7-bb33-20014ef723e5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archived  best\tdata  GRU  IFT6135-HW2-Results\tmodels.py  ptb-lm.py  RNN  TF\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "4CaDJkWslBNa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "import numpy as np\n",
        "import torch.nn.functional as F\n",
        "import math, copy, time\n",
        "from torch.autograd import Variable\n",
        "\n",
        "import argparse\n",
        "import time\n",
        "import collections\n",
        "import os\n",
        "import sys"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YB3MDaREbiIa",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Models"
      ]
    },
    {
      "metadata": {
        "id": "e0VlVk9B13sh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def clones(module, N):\n",
        "    \"\"\"\n",
        "    A helper function for producing N identical layers (each with their own parameters).\n",
        "\n",
        "    inputs:\n",
        "        module: a pytorch nn.module\n",
        "        N (int): the number of copies of that module to return\n",
        "\n",
        "    returns:\n",
        "        a ModuleList with the copies of the module (the ModuleList is itself also a module)\n",
        "    \"\"\"\n",
        "    return nn.ModuleList([copy.deepcopy(module) for _ in range(N)])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4-sLUa-Ca6uj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### RNN "
      ]
    },
    {
      "metadata": {
        "id": "glTgz_Mz2C4s",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class RNN(nn.Module): # Implement a stacked vanilla RNN with Tanh nonlinearities.\n",
        "  def __init__(self, emb_size, hidden_size, seq_len, batch_size, vocab_size, num_layers, dp_keep_prob):\n",
        "    \"\"\"\n",
        "    emb_size:     The number of units in the input embeddings\n",
        "    hidden_size:  The number of hidden units per layer\n",
        "    seq_len:      The length of the input sequences\n",
        "    vocab_size:   The number of tokens in the vocabulary (10,000 for Penn TreeBank)\n",
        "    num_layers:   The depth of the stack (i.e. the number of hidden layers at\n",
        "                  each time-step)\n",
        "    dp_keep_prob: The probability of *not* dropping out units in the\n",
        "                  non-recurrent connections.\n",
        "                  Do not apply dropout on recurrent connections.\n",
        "    \"\"\"\n",
        "    super(RNN, self).__init__()\n",
        "\n",
        "    # TODO ========================\n",
        "    # Initialization of the parameters of the recurrent and fc layers.\n",
        "    # Your implementation should support any number of stacked hidden layers\n",
        "    # (specified by num_layers), use an input embedding layer, and include fully\n",
        "    # connected layers with dropout after each recurrent layer.\n",
        "    # Note: you may use pytorch's nn.Linear, nn.Dropout, and nn.Embedding\n",
        "    # modules, but not recurrent modules.\n",
        "    #\n",
        "    # To create a variable number of parameter tensors and/or nn.Modules\n",
        "    # (for the stacked hidden layer), you may need to use nn.ModuleList or the\n",
        "    # provided clones function (as opposed to a regular python list), in order\n",
        "    # for Pytorch to recognize these parameters as belonging to this nn.Module\n",
        "    # and compute their gradients automatically. You're not obligated to use the\n",
        "    # provided clones function.\n",
        "\n",
        "\n",
        "    self.emb_size = emb_size\n",
        "    self.hidden_size = hidden_size\n",
        "    self.seq_len = seq_len\n",
        "    self.batch_size = batch_size\n",
        "    self.vocab_size = vocab_size\n",
        "    self.num_layers = num_layers\n",
        "\n",
        "    self.embedding = nn.Embedding(self.vocab_size, self.emb_size)\n",
        "\n",
        "    self.W_x = clones(nn.Linear(self.hidden_size,self.hidden_size, bias=False),self.num_layers-1)\n",
        "    self.W_x.insert(0,nn.Linear(self.emb_size,self.hidden_size, bias=False))\n",
        "\n",
        "    self.W_h = clones(nn.Linear(self.hidden_size,self.hidden_size),self.num_layers)\n",
        "    self.W_y = nn.Linear(self.hidden_size,self.vocab_size)\n",
        "\n",
        "    self.dropout = nn.Dropout(p=1-dp_keep_prob)\n",
        "\n",
        "    self.init_weights()\n",
        "\n",
        "  def init_weights(self):\n",
        "\n",
        "    # Initialize the embedding and output weights uniformly in the range [-0.1, 0.1]\n",
        "    # and output biases to 0 (in place). The embeddings should not use a bias vector.\n",
        "    # Initialize all other (i.e. recurrent and linear) weights AND biases uniformly\n",
        "    # in the range [-k, k] where k is the square root of 1/hidden_size\n",
        "\n",
        "    nn.init.uniform_(self.embedding.weight.data, -0.1, 0.1)\n",
        "\n",
        "    nn.init.uniform_(self.W_y.weight,-0.1, 0.1)\n",
        "    self.W_y.bias.data.fill_(0.0)\n",
        "\n",
        "    k = 1 / np.sqrt(self.hidden_size)\n",
        "\n",
        "    for w_x in self.W_x:\n",
        "        nn.init.uniform_(w_x.weight,-k,k)\n",
        "\n",
        "    for w_h in self.W_h:\n",
        "        nn.init.uniform_(w_h.weight,-k,k)\n",
        "        nn.init.uniform_(w_h.bias,-k,k)\n",
        "\n",
        "\n",
        "  def init_hidden(self):\n",
        "    # initialize the hidden states to zero\n",
        "    \"\"\"\n",
        "    This is used for the first mini-batch in an epoch, only.\n",
        "    \"\"\"\n",
        "    # a parameter tensor of shape (self.num_layers, self.batch_size, self.hidden_size)\n",
        "    return torch.zeros(self.num_layers, self.batch_size, self.hidden_size)\n",
        "\n",
        "\n",
        "  def forward(self, inputs, hidden):\n",
        "    # Compute the forward pass, using nested python for loops.\n",
        "    # The outer for loop should iterate over timesteps, and the\n",
        "    # inner for loop should iterate over hidden layers of the stack.\n",
        "    #\n",
        "    # Within these for loops, use the parameter tensors and/or nn.modules you\n",
        "    # created in __init__ to compute the recurrent updates according to the\n",
        "    # equations provided in the .tex of the assignment.\n",
        "    #\n",
        "    # Note that those equations are for a single hidden-layer RNN, not a stacked\n",
        "    # RNN. For a stacked RNN, the hidden states of the l-th layer are used as\n",
        "    # inputs to to the {l+1}-st layer (taking the place of the input sequence).\n",
        "\n",
        "    \"\"\"\n",
        "    Arguments:\n",
        "        - inputs: A mini-batch of input sequences, composed of integers that\n",
        "                    represent the index of the current token(s) in the vocabulary.\n",
        "                        shape: (seq_len, batch_size)\n",
        "        - hidden: The initial hidden states for every layer of the stacked RNN.\n",
        "                        shape: (num_layers, batch_size, hidden_size)\n",
        "\n",
        "    Returns:\n",
        "        - Logits for the softmax over output tokens at every time-step.\n",
        "              **Do NOT apply softmax to the outputs!**\n",
        "              Pytorch's CrossEntropyLoss function (applied in ptb-lm.py) does\n",
        "              this computation implicitly.\n",
        "                    shape: (seq_len, batch_size, vocab_size)\n",
        "        - The final hidden states for every layer of the stacked RNN.\n",
        "              These will be used as the initial hidden states for all the\n",
        "              mini-batches in an epoch, except for the first, where the return\n",
        "              value of self.init_hidden will be used.\n",
        "              See the repackage_hiddens function in ptb-lm.py for more details,\n",
        "              if you are curious.\n",
        "                    shape: (num_layers, batch_size, hidden_size)\n",
        "    \"\"\"\n",
        "    inputs = self.embedding(inputs)\n",
        "    output_sequence_logits = []\n",
        "    hidden_history = []\n",
        "\n",
        "    for t in range(self.seq_len):\n",
        "        next_hidden = []\n",
        "        for layer in range(self.num_layers):\n",
        "            dropped_out_x = self.dropout(inputs[t] if layer == 0 else next_hidden[layer-1])\n",
        "            next_hidden_value = torch.tanh(self.W_x[layer](dropped_out_x) + self.W_h[layer](hidden[layer]))\n",
        "            next_hidden.append(next_hidden_value)\n",
        "            \n",
        "            if layer==0:\n",
        "              next_hidden_value.retain_grad()\n",
        "              hidden_history.append(next_hidden_value)\n",
        "            \n",
        "        dropped_out_last_hidden = self.dropout(next_hidden[layer])\n",
        "        output_logit = self.W_y(dropped_out_last_hidden)\n",
        "        output_sequence_logits.append(output_logit)\n",
        "        hidden = torch.stack(next_hidden)\n",
        "    logits = torch.stack(output_sequence_logits)\n",
        "    return logits.view(self.seq_len, self.batch_size, self.vocab_size), hidden, hidden_history"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OhyWXLSEbAzk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### GRU"
      ]
    },
    {
      "metadata": {
        "id": "vQXF0lwR2H0z",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class GRU(nn.Module):  # Implement a stacked GRU RNN\n",
        "    \"\"\"\n",
        "        Follow the same instructions as for RNN (above), but use the equations for\n",
        "        GRU, not Vanilla RNN.\n",
        "        \"\"\"\n",
        "\n",
        "    def __init__(self, emb_size, hidden_size, seq_len, batch_size, vocab_size, num_layers, dp_keep_prob):\n",
        "        super(GRU, self).__init__()\n",
        "\n",
        "        self.emb_size = emb_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.seq_len = seq_len\n",
        "        self.batch_size = batch_size\n",
        "        self.vocab_size = vocab_size\n",
        "        self.num_layers = num_layers\n",
        "        self.dp_keep_prob = dp_keep_prob\n",
        "\n",
        "\n",
        "        # using the notation for U,W,h... as given in the assignment 2 equation\n",
        "        self.Ur = clones(nn.Linear(self.hidden_size, self.hidden_size), self.num_layers)\n",
        "\n",
        "\n",
        "        self.Uz = clones(nn.Linear(self.hidden_size, self.hidden_size), self.num_layers)\n",
        "\n",
        "        self.Uh = clones(nn.Linear(self.hidden_size, self.hidden_size), self.num_layers)\n",
        "\n",
        "        # W will have to deal with 1.input dim, then 2.later inputs from previous layers\n",
        "        self.Wr = clones(nn.Linear(self.hidden_size, self.hidden_size), self.num_layers-1)\n",
        "        self.Wr.insert(0, nn.Linear(self.emb_size, self.hidden_size, bias=False))\n",
        "\n",
        "        self.Wz = clones(nn.Linear(self.hidden_size, self.hidden_size), self.num_layers-1)\n",
        "        self.Wz.insert(0, nn.Linear(self.emb_size, self.hidden_size, bias=False))\n",
        "\n",
        "        self.Wh = clones(nn.Linear(self.hidden_size, self.hidden_size), self.num_layers-1)\n",
        "        self.Wh.insert(0, nn.Linear(self.emb_size, self.hidden_size, bias=False))\n",
        "\n",
        "        self.W_Output = nn.Linear(self.hidden_size,self.vocab_size)\n",
        "\n",
        "\n",
        "        self.dropout_layers = nn.Dropout(1-self.dp_keep_prob)\n",
        "            #[nn.Dropout(1 - self.dp_keep_prob) for _ in range(self.num_layers)]\n",
        "\n",
        "        self.embedding = nn.Embedding(self.vocab_size, self.emb_size)\n",
        "\n",
        "        self.init_weights_uniform()\n",
        "\n",
        "\n",
        "# self.fc_layer_with_dropout.apply(self.init_weights_uniform_FC)\n",
        "\n",
        "    def init_weights_uniform(self):\n",
        "        nn.init.uniform_(self.embedding.weight.data, -0.1, 0.1)\n",
        "\n",
        "        k = 1 / np.sqrt(self.hidden_size)\n",
        "\n",
        "        for w_r in self.Wr:\n",
        "            nn.init.uniform_(w_r.weight, -k, k)\n",
        "\n",
        "        for w_z in self.Wz:\n",
        "            nn.init.uniform_(w_z.weight, -k, k)\n",
        "\n",
        "        for w_h in self.Wh:\n",
        "            nn.init.uniform_(w_h.weight, -k, k)\n",
        "\n",
        "\n",
        "\n",
        "        for u_r in self.Ur:\n",
        "            nn.init.uniform_(u_r.weight, -k, k)\n",
        "            nn.init.uniform_(u_r.bias, -k, k)\n",
        "\n",
        "        for u_z in self.Uz:\n",
        "            nn.init.uniform_(u_z.weight, -k, k)\n",
        "            nn.init.uniform_(u_z.bias, -k, k)\n",
        "\n",
        "        for u_h in self.Uh:\n",
        "            nn.init.uniform_(u_h.weight, -k, k)\n",
        "            nn.init.uniform_(u_h.bias, -k, k)\n",
        "\n",
        "\n",
        "\n",
        "        nn.init.uniform_(self.W_Output.weight, -0.1, 0.1)\n",
        "        self.W_Output.bias.data.fill_(0.0)\n",
        "        return\n",
        "\n",
        "\n",
        "    def init_weights_uniform_FC(self, m):\n",
        "        if type(m) == nn.Linear:\n",
        "            torch.nn.init.uniform_(m.weight, -0.1, 0.1)\n",
        "            m.bias.data.fill_(0)\n",
        "        return\n",
        "\n",
        "\n",
        "    def init_hidden(self):\n",
        "        return torch.zeros(self.num_layers, self.batch_size, self.hidden_size)\n",
        "\n",
        "\n",
        "    # a parameter tensor of shape (self.num_layers, self.batch_size, self.hidden_size)\n",
        "\n",
        "    def layer_calculation_gru(self, x, hidden, layer):\n",
        "        x = self.dropout_layers(x)\n",
        "\n",
        "        r_pre =  self.Wr[layer](x) +  self.Ur[layer](hidden[layer])\n",
        "        r = torch.sigmoid(r_pre)\n",
        "\n",
        "        z_pre = self.Wz[layer](x) + self.Uz[layer](hidden[layer])\n",
        "        z = torch.sigmoid(z_pre)\n",
        "\n",
        "        r_hidden_layer_element_product= (r * hidden[layer])\n",
        "        h_tilda_pre = self.Wh[layer](x) + self.Uh[layer](r_hidden_layer_element_product)\n",
        "        h_tilda = torch.tanh(h_tilda_pre)\n",
        "\n",
        "        # one_minus_z = torch.ones(z.size()).to(device) - z\n",
        "        one_minus_z = 1 - z\n",
        "        h = (one_minus_z * hidden[layer]) + (z * h_tilda)\n",
        "\n",
        "        return h\n",
        "\n",
        "\n",
        "    def forward(self, inputs, hidden):\n",
        "\n",
        "        inputs = self.embedding(inputs)\n",
        "        final_output_list = []\n",
        "        hidden_history = []\n",
        "        \n",
        "        for time_in in range(self.seq_len):\n",
        "            current_input = inputs[time_in]\n",
        "            hidden_states = []\n",
        "            for layer in range(self.num_layers):\n",
        "                if layer == 0:\n",
        "                    layer_output = self.layer_calculation_gru(current_input, hidden, layer)\n",
        "                    layer_output.retain_grad()\n",
        "                    hidden_history.append(layer_output)\n",
        "                else:\n",
        "                    layer_output = self.layer_calculation_gru(hidden_states[layer - 1], hidden, layer)\n",
        "\n",
        "                hidden_states.append(layer_output)\n",
        "            last_hidden_dropout= self.dropout_layers(hidden_states[layer])\n",
        "            final_output_list.append(self.W_Output(last_hidden_dropout))\n",
        "            hidden = torch.stack(hidden_states)\n",
        "\n",
        "        return torch.stack(final_output_list), hidden, hidden_history \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-QKT_Bw4bJON",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Data Loading"
      ]
    },
    {
      "metadata": {
        "id": "KKP23Pta3pZB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# HELPER FUNCTIONS\n",
        "def _read_words(filename):\n",
        "    with open(filename, \"r\") as f:\n",
        "      return f.read().replace(\"\\n\", \"<eos>\").split()\n",
        "\n",
        "def _build_vocab(filename):\n",
        "    data = _read_words(filename)\n",
        "\n",
        "    counter = collections.Counter(data)\n",
        "    count_pairs = sorted(counter.items(), key=lambda x: (-x[1], x[0]))\n",
        "\n",
        "    words, _ = list(zip(*count_pairs))\n",
        "    word_to_id = dict(zip(words, range(len(words))))\n",
        "    id_to_word = dict((v, k) for k, v in word_to_id.items())\n",
        "\n",
        "    return word_to_id, id_to_word\n",
        "\n",
        "def _file_to_word_ids(filename, word_to_id):\n",
        "    data = _read_words(filename)\n",
        "    return [word_to_id[word] for word in data if word in word_to_id]\n",
        "\n",
        "# Processes the raw data from text files\n",
        "def ptb_raw_data(data_path=None, prefix=\"ptb\"):\n",
        "    train_path = os.path.join(data_path, prefix + \".train.txt\")\n",
        "    valid_path = os.path.join(data_path, prefix + \".valid.txt\")\n",
        "    test_path = os.path.join(data_path, prefix + \".test.txt\")\n",
        "\n",
        "    word_to_id, id_2_word = _build_vocab(train_path)\n",
        "    train_data = _file_to_word_ids(train_path, word_to_id)\n",
        "    valid_data = _file_to_word_ids(valid_path, word_to_id)\n",
        "    test_data = _file_to_word_ids(test_path, word_to_id)\n",
        "    return train_data, valid_data, test_data, word_to_id, id_2_word\n",
        "\n",
        "# Yields minibatches of data\n",
        "def ptb_iterator(raw_data, batch_size, num_steps):\n",
        "    raw_data = np.array(raw_data, dtype=np.int32)\n",
        "\n",
        "    data_len = len(raw_data)\n",
        "    batch_len = data_len // batch_size\n",
        "    data = np.zeros([batch_size, batch_len], dtype=np.int32)\n",
        "    for i in range(batch_size):\n",
        "        data[i] = raw_data[batch_len * i:batch_len * (i + 1)]\n",
        "\n",
        "    epoch_size = (batch_len - 1) // num_steps\n",
        "\n",
        "    if epoch_size == 0:\n",
        "        raise ValueError(\"epoch_size == 0, decrease batch_size or num_steps\")\n",
        "\n",
        "    for i in range(epoch_size):\n",
        "        x = data[:, i*num_steps:(i+1)*num_steps]\n",
        "        y = data[:, i*num_steps+1:(i+1)*num_steps+1]\n",
        "        yield (x, y)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KqxZSCm3TaVS",
        "colab_type": "code",
        "outputId": "29a5ad4e-4a49-4841-b45c-c065d066d3a7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "print('Loading data from ./data')\n",
        "raw_data = ptb_raw_data(data_path='data')\n",
        "train_data, valid_data, test_data, word_to_id, id_2_word = raw_data\n",
        "vocab_size = len(word_to_id)\n",
        "print('  vocabulary size: {}'.format(vocab_size))"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading data from ./data\n",
            "  vocabulary size: 10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "yeXpJCl6UHnO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# LOSS FUNCTION\n",
        "loss_fn = nn.CrossEntropyLoss()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "g87jqL3jWNV7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "torch.manual_seed(1111)\n",
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "a8IswMAfToeA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "###############################################################################\n",
        "#\n",
        "# DEFINE COMPUTATIONS FOR PROCESSING ONE EPOCH\n",
        "#\n",
        "###############################################################################\n",
        "\n",
        "def repackage_hidden(h):\n",
        "    \"\"\"\n",
        "    Wraps hidden states in new Tensors, to detach them from their history.\n",
        "\n",
        "    This prevents Pytorch from trying to backpropagate into previous input\n",
        "    sequences when we use the final hidden states from one mini-batch as the\n",
        "    initial hidden states for the next mini-batch.\n",
        "\n",
        "    Using the final hidden states in this way makes sense when the elements of\n",
        "    the mini-batches are actually successive subsequences in a set of longer sequences.\n",
        "    This is the case with the way we've processed the Penn Treebank dataset.\n",
        "    \"\"\"\n",
        "    if isinstance(h, Variable):\n",
        "        return h.detach_()\n",
        "    else:\n",
        "        return tuple(repackage_hidden(v) for v in h)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8b2jO4IAbPgw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Computation of final-timestep loss gradient norm ($ \\nabla_{h_t} \\; L_T$)"
      ]
    },
    {
      "metadata": {
        "id": "Z-pgMkR-UEBg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def compute_validation_loss_gradient_norms(model, data):\n",
        "    \"\"\"\n",
        "    One epoch of validation\n",
        "    \"\"\"\n",
        "    model.train()\n",
        "    hidden = model.init_hidden()\n",
        "    hidden = hidden.to(device)\n",
        "\n",
        "    # LOOP THROUGH MINIBATCHES\n",
        "    for step, (x, y) in enumerate(ptb_iterator(data, model.batch_size, model.seq_len)):\n",
        "        inputs = torch.from_numpy(x.astype(np.int64)).transpose(0, 1).contiguous().to(device)#.cuda()\n",
        "        model.zero_grad()\n",
        "        hidden = repackage_hidden(hidden)\n",
        "        outputs, hidden, hidden_history = model(inputs, hidden)\n",
        "\n",
        "        outputs = outputs[-1].view(1, model.batch_size, -1)\n",
        "        targets = torch.from_numpy(y[:,-1].reshape((-1,1)).astype(np.int64)).transpose(0, 1).contiguous().to(device)#.cuda()\n",
        "        tt = torch.squeeze(targets.view(-1, model.batch_size))\n",
        "\n",
        "        loss = loss_fn(outputs.contiguous().view(-1, model.vocab_size), tt)\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.25)\n",
        "\n",
        "        gradient_norm = [torch.norm(h_t.grad).item() for h_t in hidden_history]\n",
        "        gradient_norm = np.array(gradient_norm)\n",
        "        print(\"Unnormalized norm values : \",gradient_norm)\n",
        "        gradient_norm = gradient_norm / np.amax(gradient_norm)\n",
        "        print(\"Normalized norm values : \",gradient_norm)\n",
        "        return gradient_norm\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KssYYCdLbZ4X",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Experiment Run"
      ]
    },
    {
      "metadata": {
        "id": "HzIo0CMIULh5",
        "colab_type": "code",
        "outputId": "0f68942d-b3a4-43ef-f8f1-19373bab4653",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        }
      },
      "cell_type": "code",
      "source": [
        "###############################################################################\n",
        "#\n",
        "# INVOKING THE FUNCTION FOR ALL 3 MODELS TO COMPUTE PER-TIMESTEP LOSS\n",
        "#\n",
        "###############################################################################\n",
        "\n",
        "names = ['RNN', 'GRU']\n",
        "\n",
        "models = [ RNN(emb_size=200, hidden_size=1500,\n",
        "               seq_len=35, batch_size=20,\n",
        "               vocab_size=10000, num_layers=2,\n",
        "               dp_keep_prob=0.35),\n",
        "          \n",
        "           GRU(emb_size=200, hidden_size=1500,\n",
        "               seq_len=35, batch_size=20,\n",
        "               vocab_size=10000, num_layers=2,\n",
        "               dp_keep_prob=0.35),\n",
        "         ]\n",
        "\n",
        "\n",
        "saved_paths = ['best/best_rnn.pt','best/best_gru.pt']\n",
        "\n",
        "norms = {}\n",
        "\n",
        "for name, model, saved_path in zip(names,models,saved_paths):\n",
        "    model = model.to(device)\n",
        "    state_dict = torch.load(saved_path, map_location='cpu')\n",
        "    model.load_state_dict(state_dict)\n",
        "\n",
        "    print(\"\\n Loaded state model for \",name)\n",
        "    print(\" Computing final time-step loss gradient w.r.t. hidden states for \",name)\n",
        "\n",
        "    norm_grad_L = compute_validation_loss_gradient_norms(model, valid_data)\n",
        "    norms[name] = norm_grad_L"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Loaded state model for  RNN\n",
            " Computing final time-step loss gradient w.r.t. hidden states for  RNN\n",
            "Unnormalized norm values :  [0.07992268 0.07392823 0.07029124 0.07073215 0.07235814 0.0714862\n",
            " 0.07154754 0.07398979 0.07844    0.08177775 0.08567459 0.08896661\n",
            " 0.0914677  0.09647705 0.1011297  0.10684687 0.11230408 0.11839517\n",
            " 0.12666038 0.13634706 0.14616257 0.15831123 0.17155293 0.18899612\n",
            " 0.20988411 0.22941314 0.25509563 0.29319957 0.3394897  0.38240305\n",
            " 0.46346438 0.59219873 0.79328388 1.0982995  1.55059671]\n",
            "Normalized norm values :  [0.05154317 0.04767728 0.04533173 0.04561608 0.04666471 0.04610238\n",
            " 0.04614194 0.04771698 0.05058697 0.05273954 0.05525266 0.05737572\n",
            " 0.05898871 0.06221931 0.06521986 0.06890694 0.07242637 0.07635459\n",
            " 0.08168493 0.08793199 0.09426214 0.10209697 0.11063671 0.12188606\n",
            " 0.13535699 0.14795152 0.16451449 0.18908822 0.21894132 0.2466167\n",
            " 0.29889421 0.38191667 0.5115991  0.70830764 1.        ]\n",
            "\n",
            " Loaded state model for  GRU\n",
            " Computing final time-step loss gradient w.r.t. hidden states for  GRU\n",
            "Unnormalized norm values :  [0.10921379 0.09797312 0.09636073 0.10260332 0.10589137 0.10225082\n",
            " 0.12041198 0.11689678 0.12297311 0.1350086  0.12078308 0.12533385\n",
            " 0.14103311 0.16046964 0.15552494 0.16764599 0.18652685 0.18903485\n",
            " 0.20351973 0.22382082 0.22134012 0.2496552  0.25491998 0.27741766\n",
            " 0.31302619 0.34843862 0.37062979 0.43674439 0.47369888 0.5115419\n",
            " 0.56519485 0.65208298 0.67993969 0.7791307  0.81152987]\n",
            "Normalized norm values :  [0.13457766 0.12072644 0.11873959 0.12643197 0.13048364 0.12599761\n",
            " 0.14837652 0.14404495 0.15153245 0.16636307 0.1488338  0.15444144\n",
            " 0.17378672 0.19773719 0.19164413 0.20658018 0.22984594 0.2329364\n",
            " 0.25078526 0.27580109 0.27274427 0.30763526 0.31412273 0.34184528\n",
            " 0.38572356 0.42936019 0.45670504 0.53817414 0.58371096 0.63034266\n",
            " 0.69645599 0.80352307 0.83784924 0.96007642 1.        ]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "CSpjzlH3aymi",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Plotting"
      ]
    },
    {
      "metadata": {
        "id": "9kte28YmaXyn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from matplotlib import rc\n",
        "\n",
        "plt.style.use('ggplot')\n",
        "\n",
        "rc('figure', figsize=(8, 8))\n",
        "rc('axes', titlesize = 20, labelsize = 18, titleweight = 'bold')\n",
        "rc('xtick', labelsize = 16, color = 'black')\n",
        "rc('ytick', labelsize = 16, color = 'black')\n",
        "rc('legend', fontsize = 16, handlelength = 2)\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lBM9pJVmVkp1",
        "colab_type": "code",
        "outputId": "e309c218-6850-4830-c3c5-047e87ff691c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 530
        }
      },
      "cell_type": "code",
      "source": [
        "colors = ['red','green']\n",
        "\n",
        "plt.figure(figsize=(10,8))\n",
        "for key,value,color in zip(norms.keys(),norms.values(),colors):\n",
        "  plt.plot(value, label = key, color = color)\n",
        "plt.xlabel('t')\n",
        "plt.ylabel(r'$ \\nabla_{h_t}$'+ ' ' +'$L_T$')\n",
        "plt.title('Final time-step gradient norm')\n",
        "plt.legend()  \n",
        "plt.show()"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAnMAAAIBCAYAAAAiWjnEAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nemY+AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 720x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}